{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094248b-e8f7-46a5-8ede-8ca1703aa775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# Basic cleaning for RR intervals\n",
    "def clean_rr_intervals(rr_intervals, threshold_low=0.3, threshold_high=2.0):\n",
    "    # Identify valid intervals within the threshold range\n",
    "    valid_rr_intervals = rr_intervals[(rr_intervals >= threshold_low) & \n",
    "                                      (rr_intervals <= threshold_high)]\n",
    "    \n",
    "    # Calculate the mean of valid RR intervals\n",
    "    mean_rr = np.mean(valid_rr_intervals)\n",
    "    \n",
    "    # Replace abnormal RR intervals with the mean\n",
    "    rr_intervals = np.where((rr_intervals >= threshold_low) & \n",
    "                            (rr_intervals <= threshold_high),\n",
    "                            rr_intervals,  # Keep valid intervals as is\n",
    "                            mean_rr)       # Replace invalid intervals with the mean\n",
    "    \n",
    "    return rr_intervals\n",
    "\n",
    "# Compute heart rate from ECG with R-peak detection\n",
    "def compute_heart_rate(ecg_signal, sampling_rate):\n",
    "    ecg_signal = ecg_signal.flatten() if ecg_signal.ndim > 1 else ecg_signal\n",
    "    peaks, _ = signal.find_peaks(ecg_signal, distance=sampling_rate/2)\n",
    "    rr_intervals = np.diff(peaks) / sampling_rate\n",
    "    rr_intervals = clean_rr_intervals(rr_intervals)\n",
    "    heart_rate = 60 / rr_intervals\n",
    "    return heart_rate, rr_intervals\n",
    "\n",
    "# Resample to 4 Hz with interpolation\n",
    "def resample_to_4hz(values, timestamps, original_rate, target_rate):\n",
    "    # Create original timestamps based on the sampling rate\n",
    "    original_timestamps = np.arange(0, math.floor(len(values) / original_rate), 1 / original_rate)\n",
    "    \n",
    "    # Make sure the final timestamp matches the length of original timestamps\n",
    "    new_timestamps = timestamps\n",
    "    print(len(values), len(original_timestamps))\n",
    "    \n",
    "    # Interpolate values to fit the new 4 Hz timestamps\n",
    "    resampled_values = np.interp(new_timestamps, original_timestamps, values)\n",
    "    \n",
    "    return resampled_values\n",
    "\n",
    "\n",
    "# Calculate SDNN for HRV\n",
    "def calculate_hrv(rr_intervals):\n",
    "    return np.std(rr_intervals * 1000)\n",
    "\n",
    "# Apply lowpass filter for denoising EDA signal\n",
    "def denoise_eda(eda_signal, fs, cutoff=1):\n",
    "    nyquist = 0.5 * fs\n",
    "    b, a = butter(4, cutoff / nyquist, btype='low')\n",
    "    return filtfilt(b, a, eda_signal)\n",
    "\n",
    "# Artifact correction for EDA signal\n",
    "def preprocess_eda(eda_signal, fs=4):\n",
    "    eda_denoised = denoise_eda(eda_signal, fs)\n",
    "    return nk.eda_clean(eda_denoised, method=\"biosppy\")\n",
    "\n",
    "\n",
    "# Paths\n",
    "folder_path = r'F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\Pkl Files'\n",
    "output_folder = r'F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\csv Files_cleaned'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each file\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.pkl'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "        eda_signal = data['signal']['wrist']['EDA'].flatten()\n",
    "        ecg_signal = data['signal']['chest']['ECG'].flatten()\n",
    "        labels = data['label'].flatten()\n",
    "\n",
    "        fs_ecg = 700\n",
    "        fs_eda = 4\n",
    "\n",
    "        timestamps = np.arange(0, len(eda_signal) / fs_eda, 1 / fs_eda)  # 4 Hz timestamps\n",
    "        eda_preprocessed = preprocess_eda(eda_signal, fs=fs_eda)\n",
    "\n",
    "        heart_rate, rr_intervals = compute_heart_rate(ecg_signal, fs_ecg)    \n",
    "        \n",
    "        resampled_hr = resample_to_4hz(heart_rate, timestamps,len(heart_rate)/timestamps[-1] , fs_eda)\n",
    "        resampled_rr = resample_to_4hz(rr_intervals,timestamps, len(rr_intervals)/timestamps[-1] , fs_eda)\n",
    "        \n",
    "        # Calculate HRV dynamically for each timestamp\n",
    "        hrv_values = [calculate_hrv(resampled_rr[:np.searchsorted(timestamps, t) + 1]) for t in timestamps]\n",
    "\n",
    "        # Downsample labels to match EDA (assuming 700 Hz -> 4 Hz)\n",
    "        labels_downsampled = labels[::175]\n",
    "\n",
    "        # Ensure matching lengths\n",
    "        min_length = min(len(eda_preprocessed), len(resampled_hr), len(resampled_rr), len(labels_downsampled), len(hrv_values), len(timestamps))\n",
    "        \n",
    "        # Slice each signal to min_length\n",
    "        eda_preprocessed = eda_preprocessed[:min_length]\n",
    "        resampled_hr = resampled_hr[:min_length]\n",
    "        resampled_rr = resampled_rr[:min_length]\n",
    "        labels_downsampled = labels_downsampled[:min_length]\n",
    "        timestamps = timestamps[:min_length]\n",
    "        hrv_values = hrv_values[:min_length]\n",
    "\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'Time': timestamps,\n",
    "            'EDA': eda_preprocessed,\n",
    "            'Heart_Rate': resampled_hr,\n",
    "            'RR_Interval': resampled_rr,\n",
    "            'HRV': hrv_values,\n",
    "            'Label': labels_downsampled\n",
    "        })\n",
    "\n",
    "        subject_id = data['subject']\n",
    "        output_file_path = os.path.join(output_folder, f\"subject_{subject_id}.csv\")\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "\n",
    "        print(f\"Saved data for subject {subject_id} to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dafe28e-86be-47c5-9bfc-f29f5e56ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dataset saved to F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\combined_features_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis, variation, moment\n",
    "from scipy.signal import find_peaks, welch\n",
    "from scipy.stats import hmean, gmean, iqr, mode\n",
    "import neurokit2 as nk\n",
    "from scipy.integrate import trapezoid\n",
    "\n",
    "# Statistical Features Function with safe mode calculation\n",
    "def statistical_features(signal, type=''):\n",
    "    features = {\n",
    "        f'{type}_mean': np.mean(signal),\n",
    "        f'{type}_geometric_mean': gmean(signal) if len(signal) > 0 else np.nan,\n",
    "        f'{type}_harmonic_mean': hmean(signal) if len(signal) > 0 else np.nan,\n",
    "        f'{type}_standard_deviation': np.std(signal),\n",
    "        f'{type}_mean_absolute_deviation': np.mean(np.abs(signal - np.mean(signal))),\n",
    "        f'{type}_variance': np.var(signal),\n",
    "        f'{type}_median': np.median(signal),\n",
    "        f'{type}_maximum': np.max(signal),\n",
    "        f'{type}_minimum': np.min(signal),\n",
    "        f'{type}_25th_percentile': np.percentile(signal, 25),\n",
    "        f'{type}_75th_percentile': np.percentile(signal, 75),\n",
    "        f'{type}_range': np.max(signal) - np.min(signal),\n",
    "        f'{type}_interquartile_range': iqr(signal),\n",
    "        f'{type}_variation_coefficient': variation(signal) if len(signal) > 0 else np.nan,\n",
    "        f'{type}_central_moment': moment(signal, moment=2),\n",
    "        f'{type}_skewness': skew(signal) if len(signal) > 0 else np.nan,\n",
    "        f'{type}_kurtosis': kurtosis(signal) if len(signal) > 0 else np.nan\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Nonlinear Features Function with safe mode calculation\n",
    "def nonlinear_features(signal, type=''):\n",
    "    # Compute approximate entropy and sample entropy\n",
    "    apen, apen_info = nk.entropy_approximate(signal, delay=1, dimension=2, tolerance='sd')\n",
    "    sampen, sampen_info = nk.entropy_sample(signal, delay=1, dimension=2, tolerance='sd')\n",
    "    \n",
    "    # Store the results in the features dictionary directly\n",
    "    features = {       \n",
    "        f'{type}_approx_entropy': float(apen),  # Directly assign apen\n",
    "        f'{type}_sample_entropy': float(sampen)  # Directly assign sampen\n",
    "    }\n",
    "\n",
    "    # Compute SD1 and SD2 manually for PoincarÃ© plot features\n",
    "    rr_diff = np.diff(signal)\n",
    "    sd1 = np.sqrt(np.var(rr_diff) / 2)\n",
    "    sd2 = np.sqrt(2 * np.var(signal) - (np.var(rr_diff) / 2))\n",
    "    \n",
    "    features.update({f'{type}_SD1': sd1, f'{type}_SD2': sd2})\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def eda_features(eda_signal, fs=4):\n",
    "    eda_phasic = nk.eda_phasic(eda_signal, sampling_rate=fs)\n",
    "    scl = np.mean(eda_phasic['EDA_Tonic'])\n",
    "    peaks, _ = find_peaks(eda_phasic['EDA_Phasic'], height=0)\n",
    "    scr_amplitude = np.mean(eda_phasic['EDA_Phasic'][peaks])\n",
    "    scr_duration = np.mean(np.diff(peaks)) / fs if len(peaks) > 1 else 0\n",
    "    scr_frequency = len(peaks) / len(eda_signal)\n",
    "    return {\n",
    "        'SCL': scl,\n",
    "        'SCR Amplitude': scr_amplitude,\n",
    "        'SCR Duration': scr_duration,\n",
    "        'SCR Frequency': scr_frequency\n",
    "    }\n",
    "\n",
    "\n",
    "def hrv_time_domain(rr_intervals, fs=4):\n",
    "    rr_diff = np.diff(rr_intervals)\n",
    "    sdnn = np.std(rr_intervals)\n",
    "    avnn = np.mean(rr_intervals)\n",
    "    rmssd = np.sqrt(np.mean(rr_diff ** 2))\n",
    "    nn50 = np.sum(np.abs(rr_diff) > 0.05)\n",
    "    pnn50 = nn50 / len(rr_diff) * 100\n",
    "    sdann = np.std([np.std(rr_intervals[i:i + 5 * fs]) for i in range(0, len(rr_intervals), 5 * fs)])\n",
    "    \n",
    "    # Cardiorespiratory Arrhythmia Index (RSAindex)\n",
    "    rsa_index = (np.max(rr_intervals) - np.min(rr_intervals)) / avnn if avnn != 0 else np.nan\n",
    "    \n",
    "    # Difference in Deep Breathing (DBD)\n",
    "    dbd = np.max(rr_intervals) - np.min(rr_intervals)\n",
    "    \n",
    "    # Difference Between Exhalation and Inspiration (EI)\n",
    "    ei_ratio = np.max(rr_intervals) / np.min(rr_intervals) if np.min(rr_intervals) != 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        'SDNN': sdnn,\n",
    "        'SDANN': sdann,\n",
    "        'AVNN': avnn,\n",
    "        'RMSSD': rmssd,\n",
    "        'PNN50': pnn50,\n",
    "        'RSA Index': rsa_index,\n",
    "        'Deep Breathing Difference (DBD)': dbd,\n",
    "        'Exhalation/Inspiration Ratio (EI)': ei_ratio\n",
    "    }\n",
    "\n",
    "def hrv_frequency_domain(rr_intervals, fs=4):\n",
    "    # Using Welch's method to compute frequency-domain features\n",
    "    f, Pxx = welch(rr_intervals, fs, nperseg=256)\n",
    "    vlf_band, lf_band, hf_band = (0.003, 0.04), (0.04, 0.15), (0.15, 0.4)\n",
    "    \n",
    "    # Replacing trapz with trapezoid\n",
    "    vlf_power = trapezoid(Pxx[(f >= vlf_band[0]) & (f < vlf_band[1])])\n",
    "    lf_power = trapezoid(Pxx[(f >= lf_band[0]) & (f < lf_band[1])])\n",
    "    hf_power = trapezoid(Pxx[(f >= hf_band[0]) & (f < hf_band[1])])\n",
    "    \n",
    "    total_power = vlf_power + lf_power + hf_power\n",
    "    return {\n",
    "        'Total Power': total_power,\n",
    "        'VLF Power': vlf_power,\n",
    "        'LF Power': lf_power,\n",
    "        'HF Power': hf_power,\n",
    "        'LF/HF Ratio': lf_power / hf_power if hf_power != 0 else np.nan\n",
    "    }\n",
    "    \n",
    "\n",
    "# Paths and parameters\n",
    "input_folder = r'F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\csv Files_cleaned'\n",
    "output_file = r'F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\combined_features_dataset.csv'\n",
    "sampling_rate = 4\n",
    "segment_samples = int(5 * 60 * sampling_rate)\n",
    "overlap_samples = int(4.5 * 60 * sampling_rate)\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(input_folder, filename))\n",
    "        \n",
    "        # Segment data with 5-minute windows and 4-minute overlap\n",
    "        for start in range(0, len(df) - segment_samples + 1, segment_samples - overlap_samples):\n",
    "            end = start + segment_samples\n",
    "            segment = df.iloc[start:end].copy()\n",
    "\n",
    "            if len(segment) == segment_samples:\n",
    "                # Count each label in the segment\n",
    "                label_counts = segment['Label'].value_counts(normalize=True)\n",
    "                dominant_label = label_counts.idxmax()\n",
    "                # print(label_counts, dominant_label)\n",
    "                \n",
    "                # Extract features for EDA, HRV (RR intervals)\n",
    "                eda_data = segment['EDA'].values\n",
    "                rr_data = segment['RR_Interval'].values\n",
    "                hrv_data = segment['HRV'].values\n",
    "                \n",
    "                eda_stats = statistical_features(eda_data,\"EDA\")\n",
    "                eda_nonlinear = nonlinear_features(eda_data,\"EDA\")\n",
    "                eda_other = eda_features(eda_data, fs=sampling_rate)\n",
    "                \n",
    "                rr_stats = statistical_features(rr_data,\"HRV\")\n",
    "                rr_nonlinear = nonlinear_features(rr_data,\"HRV\")\n",
    "                rr_hrv = {**hrv_time_domain(rr_data), **hrv_frequency_domain(rr_data, fs=sampling_rate)}\n",
    "                \n",
    "                # Combine all features and label into one row\n",
    "                combined_features = {\n",
    "                    **eda_stats, **eda_nonlinear, **eda_other,\n",
    "                    **rr_stats, **rr_nonlinear, **rr_hrv,\n",
    "                    'Label': dominant_label,\n",
    "                }\n",
    "                all_features.append(combined_features)\n",
    "\n",
    "# Create a DataFrame with all extracted features and save\n",
    "combined_df = pd.DataFrame(all_features)\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"Feature dataset saved to {output_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049aed97-b324-4142-ae33-44ba0b0ec3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA-only feature dataset saved to F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\eda_features_only_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths for input and output files\n",
    "combined_features_file = r'F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\combined_features_dataset.csv'\n",
    "eda_only_output_file = r'F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\eda_features_only_dataset.csv'\n",
    "\n",
    "# Load the previously saved combined features dataset\n",
    "combined_df = pd.read_csv(combined_features_file)\n",
    "\n",
    "# Identify and filter columns based on explicit inclusion of EDA-related keywords\n",
    "eda_keywords = ['EDA', 'SCL', 'SCR Amplitude', 'SCR Duration', 'SCR Frequency', 'Label']\n",
    "eda_columns = [col for col in combined_df.columns if any(keyword in col for keyword in eda_keywords)]\n",
    "\n",
    "# Create a DataFrame with only the EDA features\n",
    "eda_df = combined_df[eda_columns]\n",
    "\n",
    "# Save the EDA-only features dataset to a new CSV file\n",
    "eda_df.to_csv(eda_only_output_file, index=False)\n",
    "print(f\"EDA-only feature dataset saved to {eda_only_output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc973ed-c657-4910-9fb4-e6b005b54a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core EDA and HRV feature dataset saved to F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\core_features_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths for input and output files\n",
    "combined_features_file = r'F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\combined_features_dataset.csv'\n",
    "core_features_output_file = r'F:\\Studies\\PainStudies Lab\\Stress Assessment\\WESAD Dataset\\WESAD\\core_features_dataset.csv'\n",
    "\n",
    "# Load the previously saved combined features dataset\n",
    "combined_df = pd.read_csv(combined_features_file)\n",
    "\n",
    "# Identify columns associated with core EDA and HRV features (excluding statistical and nonlinear features)\n",
    "core_eda_hrv_keywords = [\n",
    "    'SCL', 'SCR Amplitude', 'SCR Duration', 'SCR Frequency',  # Core EDA features\n",
    "    'SDNN', 'SDANN', 'AVNN', 'RMSSD', 'PNN50',                # Core HRV time-domain features\n",
    "    'Total Power', 'VLF Power', 'LF Power', 'HF Power', 'LF/HF Ratio',  # Core HRV frequency-domain features\n",
    "    'Label'  # Include the label column\n",
    "]\n",
    "core_columns = [col for col in combined_df.columns if any(keyword in col for keyword in core_eda_hrv_keywords)]\n",
    "\n",
    "# Create a DataFrame with only the core EDA and HRV features\n",
    "core_df = combined_df[core_columns]\n",
    "\n",
    "# Save the core features dataset to a new CSV file\n",
    "core_df.to_csv(core_features_output_file, index=False)\n",
    "print(f\"Core EDA and HRV feature dataset saved to {core_features_output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c634e6-4bf0-4e3f-91d4-e969beef3cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
