{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872905a8-a939-43f3-b626-1bd93273cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import time\n",
    "import socket\n",
    "from bleak import BleakScanner, BleakClient\n",
    "from datetime import datetime\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.stats import skew, kurtosis, variation, moment\n",
    "from scipy.signal import find_peaks, welch\n",
    "from scipy.stats import hmean, gmean, iqr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import neurokit2 as nk\n",
    "from scipy.integrate import trapezoid\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Apply nest_asyncio to allow asyncio event loop in a synchronous environment\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#-----------------------------------Setting up parameters-------------------------------     \n",
    "# Device names and UUIDs for RHYTHM24 and Moodmetric ring\n",
    "RHYTHM24_NAME = \"Rhythm 24\"\n",
    "MOODMETRIC_NAME = \"Moodmetric\"\n",
    "\n",
    "# Device UUIDs for RHYTHM24 and Moodmetric ring\n",
    "HR_MEASUREMENT_UUID = \"00002a37-0000-1000-8000-00805f9b34fb\"\n",
    "GATT_STREAM_CHAR_UUID = \"a0956420-9bd2-11e4-bd06-0800200c9a66\"\n",
    "GATT_RAW_DATA_CHAR_UUID = \"f1b41cde-dbf5-4acf-8679-ecb8b4dca6ff\"\n",
    "\n",
    "# TCP Server settings\n",
    "TCP_IP = '127.0.0.1'  # Localhost\n",
    "TCP_PORT = 5050        # Port to listen on\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = joblib.load('model.joblib')\n",
    "normalized_model = joblib.load('normalized_model.joblib')\n",
    "scaler = joblib.load(\"scaler.joblib\")\n",
    "\n",
    "sampling_rate = 3  # Hz\n",
    "SEGMENT_DURATION = int(5 * 60)  # 5 minutes in seconds\n",
    "UPDATE_DURATION = int(0.5 * 60)  # 4 minutes in seconds\n",
    "\n",
    "# Global variable to store the latest stress score and other readings\n",
    "predicted_stress_state= None\n",
    "latest_eda = None\n",
    "latest_mm_stress_score = None\n",
    "latest_rr_interval = None\n",
    "latest_hr = None\n",
    "\n",
    "eda_data = []\n",
    "rr_interval_data = []\n",
    "\n",
    "# Define a mapping dictionary\n",
    "label_mapping = {\n",
    "    0: \"neutral\",\n",
    "    1: \"stressed\",\n",
    "    2: \"amused\",\n",
    "    3: \"relaxed\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7df6c4-e2e7-42de-b2b4-2c60c2f78b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder if it doesn't exist\n",
    "current_directory = os.getcwd()  # This will give you the directory where the script is executed\n",
    "output_folder = os.path.join(current_directory, 'Readings')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# File path for storing data\n",
    "timestamp_init = datetime.now().strftime(\"%Y%m%d_%H%M\")  # Format: YYYYMMDD_HHMMSS\n",
    "combined_csv = os.path.join(output_folder, f'sensor_readings_{timestamp_init}.csv')\n",
    "\n",
    "# Write headers for the combined CSV file if it doesn't exist\n",
    "if not os.path.exists(combined_csv):\n",
    "    with open(combined_csv, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Timestamp', 'EDA data', 'MM Score','RR Interval','Heart Rate','State'])\n",
    "\n",
    "#---------------------------------------------- Function for Saving to csv ----------------------------------------------        \n",
    "def save_to_csv():\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    with open(combined_csv, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([timestamp, latest_eda, latest_mm_stress_score, latest_rr_interval, latest_hr, predicted_stress_state])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bcd009-312e-4d93-961a-9a414cca46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------- Functions to scan and connect to devices ----------------------------------------------\n",
    "# Function to scan and connect to devices\n",
    "async def connect_to_device(device_name, retries=3, scan_duration=10):\n",
    "    for attempt in range(retries):\n",
    "        print(f\"Attempt {attempt + 1} of {retries}: Scanning for {device_name}...\")\n",
    "        devices = await BleakScanner.discover(timeout=scan_duration)\n",
    "        for device in devices:\n",
    "            if device_name in str(device.name):\n",
    "                print(f\"Found {device_name}\")\n",
    "                return device\n",
    "        print(f\"{device_name} not found. Retrying...\")\n",
    "    print(f\"{device_name} not found after multiple attempts.\")\n",
    "    return None\n",
    "\n",
    "# Function to read data from RHYTHM24\n",
    "async def read_rhythm24_data(client):\n",
    "    try:\n",
    "        await client.start_notify(HR_MEASUREMENT_UUID, rhythm24_notification_handler)\n",
    "        try:\n",
    "            while True:\n",
    "                await asyncio.sleep(1)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Data collection stopped by user.\")\n",
    "        finally:\n",
    "            await client.stop_notify(HR_MEASUREMENT_UUID)\n",
    "            print(\"Notifications stopped.\")\n",
    "    except asyncio.TimeoutError:\n",
    "        print(f\"Connection to {RHYTHM24_NAME} timed out.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Function to read data from Moodmetric ring\n",
    "async def read_moodmetric_data(client):\n",
    "    try:\n",
    "        await client.start_notify(GATT_STREAM_CHAR_UUID, moodmetric_notification_handler)\n",
    "        await client.start_notify(GATT_RAW_DATA_CHAR_UUID, moodmetric_notification_handler)\n",
    "        try:\n",
    "            while True:\n",
    "                await asyncio.sleep(1)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Data collection stopped by user.\")\n",
    "        finally:\n",
    "            await client.stop_notify(GATT_STREAM_CHAR_UUID)\n",
    "            await client.stop_notify(GATT_RAW_DATA_CHAR_UUID)\n",
    "            print(\"Notifications stopped.\")\n",
    "    except asyncio.TimeoutError:\n",
    "        print(f\"Connection to {MOODMETRIC_NAME} timed out.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ac4fd-ce77-4ade-9ed7-e79033766e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------- Function to send data to Unity ----------------------------------------------\n",
    "# Function to send the latest stress score to Unity over TCP\n",
    "def send_stress_score_to_unity():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:\n",
    "        server_socket.bind((TCP_IP, TCP_PORT))\n",
    "        server_socket.listen(1)  # Listen for a single client connection\n",
    "        print(f\"Waiting for connection on {TCP_IP}:{TCP_PORT}...\")\n",
    "        print(\"Do not close the program! It might take some time...\")\n",
    "\n",
    "        client_socket, client_address = server_socket.accept()\n",
    "        with client_socket:\n",
    "            print(f\"Client connected: {client_address}\")\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    global predicted_stress_score\n",
    "                    if predicted_stress_score is not None:\n",
    "                        # Send the latest stress score as a string followed by a newline\n",
    "                        stress_score_str = f\"{predicted_stress_score}\\n\"\n",
    "                        client_socket.sendall(stress_score_str.encode())\n",
    "\n",
    "                    time.sleep(0.01)\n",
    "\n",
    "            except (ConnectionResetError, BrokenPipeError):\n",
    "                print(\"Client disconnected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356a92a-4823-40b6-92c2-b6f01b76eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------- Functions to extract features ----------------------------------------------\n",
    "# Basic cleaning for RR intervals\n",
    "def clean_rr_intervals(rr_intervals, threshold_low=0.3, threshold_high=2.0):\n",
    "    valid_rr_intervals = rr_intervals[(rr_intervals >= threshold_low) & (rr_intervals <= threshold_high)]\n",
    "    mean_rr = np.mean(valid_rr_intervals)\n",
    "    rr_intervals = np.where((rr_intervals >= threshold_low) & (rr_intervals <= threshold_high), rr_intervals, mean_rr)\n",
    "    return rr_intervals\n",
    "\n",
    "# Resample to a new sampling rate with interpolation\n",
    "def resample(values, target_timestamps, original_rate):\n",
    "    if len(values) == 0 or len(target_timestamps) == 0:\n",
    "        return np.array([])\n",
    "    original_timestamps = np.arange(0, len(values) / original_rate, 1 / original_rate)\n",
    "    min_length = min(len(values), len(original_timestamps))\n",
    "    values = values[:min_length]\n",
    "    original_timestamps = original_timestamps[:min_length]\n",
    "    # print(f\"Lengths - Values: {len(values)}, Original Timestamps: {len(original_timestamps)}, Target Timestamps: {len(target_timestamps)}\")\n",
    "    resampled_values = np.interp(target_timestamps, original_timestamps, values)\n",
    "    return resampled_values\n",
    "\n",
    "# Calculate SDNN for HRV\n",
    "def calculate_hrv(rr_intervals):\n",
    "    return np.std(rr_intervals * 1000)\n",
    "\n",
    "# Lowpass filter for denoising EDA signal\n",
    "def denoise_eda(eda_signal, fs, cutoff=1):\n",
    "    nyquist = 0.5 * fs\n",
    "    b, a = butter(4, cutoff / nyquist, btype='low')\n",
    "    return filtfilt(b, a, eda_signal)\n",
    "\n",
    "# Artifact correction for EDA signal\n",
    "def preprocess_eda(eda_signal, fs):\n",
    "    eda_denoised = denoise_eda(eda_signal, fs)\n",
    "    return nk.eda_clean(eda_denoised, method=\"biosppy\")\n",
    "\n",
    "# Statistical Features\n",
    "def statistical_features(signal, type=''):\n",
    "    features = {\n",
    "        f'{type}_mean': np.mean(signal),\n",
    "        f'{type}_geometric_mean': gmean(signal) if len(signal) > 0 else np.nan,\n",
    "        f'{type}_harmonic_mean': hmean(signal) if len(signal) > 0 else np.nan,\n",
    "        f'{type}_standard_deviation': np.std(signal),\n",
    "        f'{type}_mean_absolute_deviation': np.mean(np.abs(signal - np.mean(signal))),\n",
    "        f'{type}_variance': np.var(signal),\n",
    "        f'{type}_median': np.median(signal),\n",
    "        f'{type}_maximum': np.max(signal),\n",
    "        f'{type}_minimum': np.min(signal),\n",
    "        f'{type}_25th_percentile': np.percentile(signal, 25),\n",
    "        f'{type}_75th_percentile': np.percentile(signal, 75),\n",
    "        f'{type}_range': np.max(signal) - np.min(signal),\n",
    "        f'{type}_interquartile_range': iqr(signal),\n",
    "        f'{type}_variation_coefficient': variation(signal) if len(signal) > 0 else np.nan,\n",
    "        f'{type}_central_moment': moment(signal, moment=2),\n",
    "        f'{type}_skewness': skew(signal) if len(signal) > 0 else np.nan,\n",
    "        f'{type}_kurtosis': kurtosis(signal) if len(signal) > 0 else np.nan\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Nonlinear Features Function with safe mode calculation\n",
    "def nonlinear_features(signal, type=''):\n",
    "    # Compute approximate entropy and sample entropy\n",
    "    apen, apen_info = nk.entropy_approximate(signal, delay=1, dimension=2, tolerance='sd')\n",
    "    sampen, sampen_info = nk.entropy_sample(signal, delay=1, dimension=2, tolerance='sd')\n",
    "    \n",
    "    # Store the results in the features dictionary directly\n",
    "    features = {       \n",
    "        f'{type}_approx_entropy': float(apen),  # Directly assign apen\n",
    "        f'{type}_sample_entropy': float(sampen)  # Directly assign sampen\n",
    "    }\n",
    "\n",
    "    # Compute SD1 and SD2 manually for Poincaré plot features\n",
    "    rr_diff = np.diff(signal)\n",
    "    sd1 = np.sqrt(np.var(rr_diff) / 2)\n",
    "    sd2 = np.sqrt(2 * np.var(signal) - (np.var(rr_diff) / 2))\n",
    "    \n",
    "    features.update({f'{type}_SD1': sd1, f'{type}_SD2': sd2})\n",
    "    return features\n",
    "\n",
    "# EDA Features\n",
    "def eda_features(eda_signal, fs=4):\n",
    "    eda_phasic = nk.eda_phasic(eda_signal, sampling_rate=fs)\n",
    "    scl = np.mean(eda_phasic['EDA_Tonic'])\n",
    "    peaks, _ = find_peaks(eda_phasic['EDA_Phasic'], height=0)\n",
    "    scr_amplitude = np.mean(eda_phasic['EDA_Phasic'][peaks])\n",
    "    scr_duration = np.mean(np.diff(peaks)) / fs if len(peaks) > 1 else 0\n",
    "    scr_frequency = len(peaks) / len(eda_signal)\n",
    "    return {\n",
    "        'SCL': scl,\n",
    "        'SCR Amplitude': scr_amplitude,\n",
    "        'SCR Duration': scr_duration,\n",
    "        'SCR Frequency': scr_frequency\n",
    "    }\n",
    "\n",
    "# HRV Time-Domain Features\n",
    "def hrv_time_domain(rr_intervals, fs=4):\n",
    "    rr_diff = np.diff(rr_intervals)\n",
    "    sdnn = np.std(rr_intervals)\n",
    "    avnn = np.mean(rr_intervals)\n",
    "    rmssd = np.sqrt(np.mean(rr_diff ** 2))\n",
    "    nn50 = np.sum(np.abs(rr_diff) > 0.05)\n",
    "    pnn50 = nn50 / len(rr_diff) * 100\n",
    "    sdann = np.std([np.std(rr_intervals[i:i + 5 * fs]) for i in range(0, len(rr_intervals), 5 * fs)])\n",
    "    rsa_index = (np.max(rr_intervals) - np.min(rr_intervals)) / avnn if avnn != 0 else np.nan\n",
    "    dbd = np.max(rr_intervals) - np.min(rr_intervals)\n",
    "    ei_ratio = np.max(rr_intervals) / np.min(rr_intervals) if np.min(rr_intervals) != 0 else np.nan\n",
    "    return {\n",
    "        'SDNN': sdnn,\n",
    "        'SDANN': sdann,\n",
    "        'AVNN': avnn,\n",
    "        'RMSSD': rmssd,\n",
    "        'PNN50': pnn50,\n",
    "        'RSA Index': rsa_index,\n",
    "        'Deep Breathing Difference (DBD)': dbd,\n",
    "        'Exhalation/Inspiration Ratio (EI)': ei_ratio\n",
    "    }\n",
    "\n",
    "# HRV Frequency-Domain Features\n",
    "def hrv_frequency_domain(rr_intervals, fs=4):\n",
    "    f, Pxx = welch(rr_intervals, fs, nperseg=256)\n",
    "    vlf_band, lf_band, hf_band = (0.003, 0.04), (0.04, 0.15), (0.15, 0.4)\n",
    "    vlf_power = trapezoid(Pxx[(f >= vlf_band[0]) & (f < vlf_band[1])])\n",
    "    lf_power = trapezoid(Pxx[(f >= lf_band[0]) & (f < lf_band[1])])\n",
    "    hf_power = trapezoid(Pxx[(f >= hf_band[0]) & (f < hf_band[1])])\n",
    "    total_power = vlf_power + lf_power + hf_power\n",
    "    return {\n",
    "        'Total Power': total_power,\n",
    "        'VLF Power': vlf_power,\n",
    "        'LF Power': lf_power,\n",
    "        'HF Power': hf_power,\n",
    "        'LF/HF Ratio': lf_power / hf_power if hf_power != 0 else np.nan\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600c87d-315c-462d-9293-8c4804fd01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------- Functions to handle sensors' data ----------------------------------------------\n",
    "# Function to handle Moodmetric notifications\n",
    "def moodmetric_notification_handler(sender, data):\n",
    "    global latest_eda, latest_mm_stress_score, eda_data, rr_interval_data, sampling_rate, start_time\n",
    "    # print(len(rr_interval_data))\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    if GATT_STREAM_CHAR_UUID in str(sender):\n",
    "        mm_score = data[1]\n",
    "        latest_mm_stress_score = mm_score  # This function should be defined or imported in the main code\n",
    "        # print(f\"Received MM Score (Stress Level): {mm_score} at {timestamp}\")\n",
    "    elif GATT_RAW_DATA_CHAR_UUID in str(sender):\n",
    "        latest_eda = int.from_bytes(data[0:2], byteorder='big') / 1000\n",
    "        eda_data.append(latest_eda)\n",
    "        # print(f\"Received raw EDA data: {latest_eda} at {timestamp}\")   \n",
    "    save_to_csv()  # This function should also be defined or imported in the main code\n",
    "    len_eda_data = len(eda_data)\n",
    "    len_segment = sampling_rate * SEGMENT_DURATION\n",
    "    if (elapsed_time >= SEGMENT_DURATION) & (int(elapsed_time) % UPDATE_DURATION == 0) & (len(eda_data) > sampling_rate):\n",
    "        predict_state(eda_data, rr_interval_data, sampling_rate)\n",
    "        eda_data = []\n",
    "        rr_interval_data = []\n",
    "        \n",
    "\n",
    "# Function to handle RHYTHM24 heart rate notifications\n",
    "def rhythm24_notification_handler(sender, data):\n",
    "    global latest_hr, latest_rr_interval, rr_interval_data\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    if HR_MEASUREMENT_UUID in str(sender):\n",
    "        flags = data[0]\n",
    "        latest_hr = data[1]\n",
    "        # print(f\"Received Heart Rate data: {latest_hr} at {timestamp}\")\n",
    "        rr_intervals_present = flags & 0x10\n",
    "        if rr_intervals_present:\n",
    "            rr_count = (len(data) - 2) // 2\n",
    "            rr_intervals = []\n",
    "            for i in range(rr_count):\n",
    "                latest_rr_interval = int.from_bytes(data[2 + i * 2:4 + i * 2], byteorder=\"little\") / 1024\n",
    "                # print(f\"Received RR Interval data: {latest_rr_interval} at {timestamp}\")\n",
    "                rr_intervals.append(latest_rr_interval)\n",
    "            rr_intervals = np.array(rr_intervals).flatten().tolist() \n",
    "            rr_interval_data.extend(rr_intervals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c974e4-b571-420a-8957-4e597489a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------- Function to predict state ----------------------------------------------\n",
    "def predict_state(eda_signal, rr_intervals, sampling_rate):\n",
    "    global predicted_stress_state\n",
    "    print(\"Starting to predict...\")\n",
    "    # starting_time = datetime.now() \n",
    "    cleaned_eda = preprocess_eda(eda_signal, fs=sampling_rate)\n",
    "    \n",
    "    eda_timestamps = np.arange(0, len(eda_signal) / sampling_rate, 1 / sampling_rate)\n",
    "    org_rr_rate = len(rr_intervals) / eda_timestamps[-1]\n",
    "    resampled_rr = resample(rr_intervals, eda_timestamps, org_rr_rate)\n",
    "    \n",
    "    eda_stats = statistical_features(cleaned_eda, \"EDA\")\n",
    "    eda_nonlinear = nonlinear_features(cleaned_eda, \"EDA\")\n",
    "    eda_other = eda_features(cleaned_eda, fs=sampling_rate)   \n",
    "    \n",
    "    rr_stats = statistical_features(resampled_rr, \"HRV\")\n",
    "    rr_nonlinear = nonlinear_features(resampled_rr, \"HRV\")\n",
    "    rr_hrv = {**hrv_time_domain(resampled_rr), **hrv_frequency_domain(resampled_rr, fs = sampling_rate)}\n",
    "    \n",
    "    # Convert combined features to DataFrame for model prediction\n",
    "    combined_features = {**eda_stats, **eda_nonlinear, **eda_other, **rr_stats, **rr_nonlinear, **rr_hrv}\n",
    "    combined_features_df = pd.DataFrame([combined_features])\n",
    "    combined_features_df = scaler.transform(combined_features_df)\n",
    "\n",
    "    # Predict using the model\n",
    "    predicted_stress_label = normalized_model.predict(combined_features_df)[0]\n",
    "    predicted_stress_state = label_mapping[predicted_stress_label]\n",
    "    print(\"MM Score:\", latest_mm_stress_score, \"State:\", predicted_stress_state, \"label:\", predicted_stress_label)\n",
    "    # elapsed_time_ms = int((datetime.now() - starting_time).total_seconds() * 1000)\n",
    "    # print(\"Elapsed time\", elapsed_time_ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74d83c-6076-4bc6-8bd0-06fca6a916c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------Main function-------------------------------\n",
    "# Main function to run both RHYTHM24 and Moodmetric data collection concurrently if both are connected\n",
    "async def main():\n",
    "    global start_time\n",
    "    rhythm24_device = await connect_to_device(RHYTHM24_NAME)\n",
    "    moodmetric_device = await connect_to_device(MOODMETRIC_NAME)\n",
    "\n",
    "    if rhythm24_device and moodmetric_device:\n",
    "        print(\"Both RHYTHM24 and Moodmetric ring are connected. Starting data collection...\")\n",
    "\n",
    "        # Start TCP server in a separate thread\n",
    "        # threading.Thread(target=send_stress_score_to_unity, daemon=True).start()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        async with BleakClient(rhythm24_device) as rhythm24_client, BleakClient(moodmetric_device) as moodmetric_client:\n",
    "            await asyncio.gather(\n",
    "                read_rhythm24_data(rhythm24_client),\n",
    "                read_moodmetric_data(moodmetric_client)\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        print(\"Data collection aborted because both devices are not connected.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import threading\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870728c-99f8-4f0a-9c99-cdc0d41380ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
